{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c7b0cd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Thu Apr  7 12:35:34 2022\n",
    "\n",
    "@author: shahina\n",
    "\"\"\"\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import os\n",
    "\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense,Dropout,Flatten\n",
    "from tensorflow.keras.layers import Conv2D,MaxPooling2D,Activation\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "train_dir = input(\"Enter path of train dataset  : \")#/home/shahina/Documents/ML/VOC/dataset3/train\n",
    "val_dir=input(\"Enter path of validation dataset  : \")#/home/shahina/Documents/ML/VOC/dataset3/validate\n",
    "\n",
    "# function to get count of images\n",
    "def get_files(directory):\n",
    "  if not os.path.exists(directory):\n",
    "    return 0\n",
    "  count=0\n",
    "  for current_path,dirs,files in os.walk(directory):\n",
    "    for dr in dirs:\n",
    "      count += len(glob.glob(os.path.join(current_path,dr+\"/*\")))\n",
    "  return count\n",
    "\n",
    "train_samples =get_files(train_dir)\n",
    "num_classes=len(glob.glob(train_dir+\"/*\"))\n",
    "\n",
    "print(num_classes,\"Classes\")\n",
    "print(train_samples,\"Train images\")\n",
    "\n",
    "# Preprocessing data.\n",
    "train_datagen=ImageDataGenerator()\n",
    "\n",
    "val_datagen=ImageDataGenerator()\n",
    "\n",
    "# set height and width and color of input image.\n",
    "img_width,img_height =224,224\n",
    "input_shape=(img_width,img_height,3)\n",
    "batch_size =64\n",
    "train_generator = train_datagen.flow_from_directory(train_dir,\n",
    "                                                   target_size=(img_width,img_height),\n",
    "                                                   batch_size=batch_size)\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (5, 5),input_shape=input_shape,activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(3, 3)))\n",
    "model.add(Conv2D(32, (3, 3),activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Conv2D(64, (3, 3),activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))   \n",
    "model.add(Flatten())\n",
    "model.add(Dense(128,activation='relu'))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(32,activation='relu'))          \n",
    "model.add(Dense(num_classes,activation='softmax'))\n",
    "model.summary()\n",
    "\n",
    "# validation data.\n",
    "validation_generator = val_datagen.flow_from_directory(val_dir, target_size=(img_height, img_width),batch_size=batch_size)\n",
    "\n",
    "# Model building to get trained with parameters.\n",
    "opt=tf.keras.optimizers.SGD(lr=0.001)\n",
    "model.compile(optimizer=opt,loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "train=model.fit_generator(train_generator,\n",
    "                          epochs=25,\n",
    "                          steps_per_epoch=train_generator.samples // batch_size,\n",
    "                          validation_data=validation_generator,\n",
    "                          verbose=1)\n",
    "\n",
    "acc = model.history.history['accuracy']\n",
    "val_acc = model.history.history['val_accuracy']\n",
    "\n",
    "loss = model.history.history['loss']\n",
    "val_loss = model.history.history['val_loss']\n",
    "\n",
    "epochs = range(1, len(acc) + 1)\n",
    "#Train and validation accuracy\n",
    "plt.plot(epochs, acc, 'b', label='Training accurarcy')\n",
    "plt.plot(epochs, val_acc, 'r', label='Validation accurarcy')\n",
    "plt.title('Training and Validation accurarcy')\n",
    "plt.legend()\n",
    "plt.figure()\n",
    "plt.savefig('accuracy.png')\n",
    "\n",
    "#Train and validation loss\n",
    "plt.plot(epochs, loss, 'b', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'r', label='Validation loss')\n",
    "plt.title('Training and Validation loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "plt.savefig('loss.png')\n",
    "\n",
    "# Save entire model with optimizer, architecture, weights and training configuration.\n",
    "from tensorflow.keras.models import load_model\n",
    "model.save('SARS_CoV_2_VOC_Net.h5', include_optimizer=True)\n",
    "\n",
    "# Save model weights.\n",
    "from tensorflow.keras.models import load_model\n",
    "model.save_weights('SARS_CoV_2_VOC_Net_weights.h5')\n",
    "\n",
    "# Loading model and predict.\n",
    "from tensorflow.keras.models import load_model\n",
    "model=load_model('SARS_CoV_2_VOC_Net.h5')\n",
    "\n",
    "#Testing the model\n",
    "\n",
    "import os\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "from sklearn.metrics import confusion_matrix,classification_report\n",
    "\n",
    "#%matplotlib inline\n",
    "\n",
    "test_dir= input(\" Enter path of test dataset  : \" )#/home/shahina/Documents/ML/VOC/dataset3/test\n",
    "img_width,img_height =224,224\n",
    "input_shape=(img_width,img_height,3)\n",
    "batch_size =64\n",
    "\n",
    "test_datagen=ImageDataGenerator()\n",
    "test_generator=test_datagen.flow_from_directory(test_dir,shuffle=False,\n",
    "                                                   target_size=(img_width,img_height),\n",
    "                                                   batch_size=batch_size)\n",
    "classes = test_generator.class_indices \n",
    "\n",
    "score,accuracy =model.evaluate_generator(test_generator,verbose=1)\n",
    "print(\"Test loss is {}\".format(score))\n",
    "print(\"Test accuracy is {}\".format(accuracy))\n",
    "\n",
    "import numpy \n",
    "\n",
    "predictions = model.predict(test_generator)\n",
    "\n",
    "# Get most likely class\n",
    "predicted_classes = numpy.argmax(predictions, axis=1)\n",
    "\n",
    "true_classes = test_generator.classes\n",
    "class_labels = list(test_generator.class_indices.keys()) \n",
    "\n",
    "import sklearn.metrics as metrics\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "report = metrics.classification_report(true_classes, predicted_classes, target_names=classes)\n",
    "print(report) \n",
    "\n",
    "print('Confusion Matrix')\n",
    "print(confusion_matrix(true_classes, predicted_classes))\n",
    "\n",
    "def plot_confusion_matrix(true_classes, predicted_classes, classes,\n",
    "                          normalize=False,\n",
    "                          title=None,\n",
    "                          cmap=plt.cm.Blues):\n",
    "\n",
    "    if not title:\n",
    "        if normalize:\n",
    "            title = 'Normalized confusion matrix'\n",
    "        else:\n",
    "            title = 'Confusion matrix, without normalization'\n",
    "\n",
    "    #Compute confusion matrix\n",
    "    cm = confusion_matrix(true_classes, predicted_classes)\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(7,7))\n",
    "    im = ax.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    ax.figure.colorbar(im, ax=ax)\n",
    "    # We want to show all ticks...\n",
    "    ax.set(xticks=np.arange(cm.shape[1]),\n",
    "           yticks=np.arange(cm.shape[0]),\n",
    "           # ... and label them with the respective list entries\n",
    "           xticklabels=classes, yticklabels=classes,\n",
    "           title=title,\n",
    "           ylabel='True label',\n",
    "           xlabel='Predicted label')\n",
    "\n",
    "\n",
    "    #Rotate the tick labels and set their alignment.\n",
    "    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",\n",
    "             rotation_mode=\"anchor\")\n",
    "    # Loop over data dimensions and create text annotations.\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i in range(cm.shape[0]):\n",
    "        for j in range(cm.shape[1]):\n",
    "            ax.text(j, i, format(cm[i, j], fmt),\n",
    "                    ha=\"center\", va=\"center\",\n",
    "                    color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "    fig.tight_layout()\n",
    "    plt.savefig('confusion_matrix.png')\n",
    "    return ax\n",
    "    \n",
    "np.set_printoptions(precision=2)\n",
    "\n",
    "classes = test_generator.class_indices \n",
    "\n",
    "# Plotting non-normalized confusion matrix\n",
    "plot_confusion_matrix(true_classes, predicted_classes, classes, title='Confusion matrix')\n",
    "\n",
    "from itertools import cycle\n",
    "\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "\n",
    "from scipy import interp\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# Compute ROC curve and ROC area for each class\n",
    "# roc curve for classes\n",
    "fpr = {}\n",
    "tpr = {}\n",
    "thresh ={}\n",
    "\n",
    "n_classes = 5\n",
    "\n",
    "for i in range(n_classes):    \n",
    "    fpr[i], tpr[i], thresh[i] = roc_curve(true_classes, predictions[:,i], pos_label=i)\n",
    "\n",
    "# plotting    \n",
    "plt.plot(fpr[0], tpr[0], linestyle='--',color='orange', label='Class 0 vs Rest')\n",
    "plt.plot(fpr[1], tpr[1], linestyle='--',color='green', label='Class 1 vs Rest')\n",
    "plt.plot(fpr[2], tpr[2], linestyle='--',color='blue', label='Class 2 vs Rest')\n",
    "plt.plot(fpr[0], tpr[0], linestyle='--',color='black', label='Class 3 vs Rest')\n",
    "plt.plot(fpr[1], tpr[1], linestyle='--',color='pink', label='Class 4 vs Rest')\n",
    "plt.title('Multiclass ROC curve')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive rate')\n",
    "plt.ylim([0.96, 1.001])\n",
    "plt.legend(loc='best')\n",
    "plt.savefig('Multiclass_ROC',dpi=300);  \n",
    "\n",
    "\n",
    "roc_auc = dict()\n",
    "for i in range(n_classes):\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "\n",
    "# First aggregate all false positive rates\n",
    "all_fpr = np.unique(np.concatenate([fpr[i] for i in range(n_classes)]))\n",
    "lw=2\n",
    "# Then interpolate all ROC curves at this points\n",
    "mean_tpr = np.zeros_like(all_fpr)\n",
    "for i in range(n_classes):\n",
    "    mean_tpr += interp(all_fpr, fpr[i], tpr[i])\n",
    "\n",
    "# Finally average it and compute AUC\n",
    "mean_tpr /= n_classes\n",
    "\n",
    "fpr[\"macro\"] = all_fpr\n",
    "tpr[\"macro\"] = mean_tpr\n",
    "roc_auc[\"macro\"] = auc(fpr[\"macro\"], tpr[\"macro\"])\n",
    "\n",
    "# Plot all ROC curves\n",
    "plt.figure()\n",
    "\n",
    "plt.plot(fpr[\"macro\"], tpr[\"macro\"],\n",
    "         label='macro-average ROC curve (area = {0:0.2f})'\n",
    "               ''.format(roc_auc[\"macro\"]),\n",
    "         color='navy', linestyle=':', linewidth=4)\n",
    "\n",
    "colors = cycle(['aqua', 'darkorange', 'cornflowerblue', 'green', 'blue', 'olive', 'brown', 'black', 'gray', 'purple'])\n",
    "for i, color in zip(range(n_classes), colors):\n",
    "    plt.plot(fpr[i], tpr[i], color=color, lw=lw,\n",
    "             label='ROC curve of class {0} (area = {1:0.2f})'\n",
    "             ''.format(i, roc_auc[i]))\n",
    "\n",
    "plt.plot([0, 1], [0, 1], 'k--', lw=lw)\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.0])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title(' Receiver operating characteristic')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.savefig('All_ROC',dpi=300)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
