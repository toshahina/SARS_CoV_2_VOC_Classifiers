{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1929e8dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Thu Apr  7 13:13:24 2022\n",
    "\n",
    "@author: shahina\n",
    "\"\"\"\n",
    "import math\n",
    "from tensorflow.keras.layers import Input, Lambda, Dense, Flatten\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "from tensorflow.keras.applications.vgg16 import preprocess_input, decode_predictions\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from  sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "import itertools \n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import auc\n",
    "\n",
    "IMAGE_SIZE = [224, 224]\n",
    "\n",
    "vgg16 = VGG16(input_shape=IMAGE_SIZE + [3], weights='imagenet', include_top=False)\n",
    "\n",
    "for layer in vgg16.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "train_dir = input(\"Enter path of training dataset : \")\n",
    "validation_dir = input (\" Enter path of validation dataset : \")\n",
    "test_dir = input (\" Enter path of test dataset : \")\n",
    "\n",
    "folders = glob(train_dir + \"/*\")\n",
    "print(\"output:\",folders)\n",
    "x = Flatten()(vgg16.output)\n",
    "prediction = Dense(len(folders), activation='softmax')(x)\n",
    "\n",
    "# create a model object\n",
    "model = Model(inputs=vgg16.input, outputs=prediction)\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(\n",
    "  loss='categorical_crossentropy',\n",
    "  optimizer='adam',\n",
    "  metrics=['accuracy']\n",
    ")\n",
    "\n",
    "batch_size = 64\n",
    "\n",
    "# Use the Image Data Generator to import the images from the dataset\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "train_datagen = ImageDataGenerator(preprocessing_function = preprocess_input)\n",
    "\n",
    "validation_datagen = ImageDataGenerator(preprocessing_function = preprocess_input)\n",
    "\n",
    "test_datagen = ImageDataGenerator(preprocessing_function = preprocess_input)\n",
    "\n",
    "training_set = train_datagen.flow_from_directory(train_dir,\n",
    "                                                 target_size=(224, 224),\n",
    "                                                 batch_size = batch_size,\n",
    "                                                 class_mode = 'categorical')\n",
    "validation_set = validation_datagen.flow_from_directory(validation_dir,\n",
    "                                                 target_size = (224, 224),\n",
    "                                                 batch_size = batch_size,\n",
    "                                                 class_mode = 'categorical')\n",
    "\n",
    "test_set = test_datagen.flow_from_directory(test_dir,\n",
    "                                            target_size = (224, 224),\n",
    "                                            batch_size = 1,\n",
    "                                            class_mode = 'categorical', \n",
    "                                            shuffle=False)\n",
    "print(\"Training set\",len(training_set))\n",
    "print(\"Validation set\",len(validation_set))\n",
    "nb_train_samples = len(training_set)\n",
    "nb_validation_samples = len(validation_set)\n",
    "nb_test_samples= len(test_set)\n",
    "\n",
    "compute_steps_per_epoch = lambda x: int(math.ceil(1. * x / batch_size))\n",
    "\n",
    "steps_per_epoch = compute_steps_per_epoch(nb_train_samples)\n",
    "val_steps = compute_steps_per_epoch(nb_validation_samples)\n",
    "print(\"valsteps is : \", val_steps)\n",
    "epochs=25\n",
    "\n",
    "r = model.fit(\n",
    "  training_set,\n",
    "  validation_data=validation_set,\n",
    "  epochs=epochs,\n",
    "  steps_per_epoch=steps_per_epoch,\n",
    "  validation_steps=val_steps\n",
    ")\n",
    "\n",
    "# Save entire model with optimizer, architecture, weights and training configuration.\n",
    "from tensorflow.keras.models import load_model\n",
    "model.save('VOC_vgg16.h5', include_optimizer=True)\n",
    "\n",
    "model.save_weights('VOC_vgg16weights.h5')\n",
    "\n",
    "test_score = model.evaluate(test_set, batch_size)\n",
    "\n",
    "print(\"[INFO] accuracy: {:.2f}%\".format(test_score[1] * 100)) \n",
    "\n",
    "print(\"[INFO] Loss: \",test_score[0])\n",
    "\n",
    "# plot the loss curves\n",
    "plt.figure(figsize=[8,6])\n",
    "\n",
    "plt.plot(r.history['loss'],'r',linewidth=3.0)\n",
    "\n",
    "plt.plot(r.history['val_loss'],'b',linewidth=3.0)\n",
    "\n",
    "plt.legend(['Training loss', 'Validation Loss'],fontsize=18)\n",
    "\n",
    "plt.xlabel('Epochs ',fontsize=16)\n",
    "\n",
    "plt.ylabel('Loss',fontsize=16)\n",
    "\n",
    "plt.title('Loss Curves',fontsize=16)\n",
    "plt.savefig('loss.png)\n",
    "#plt.savefig('LossVal_loss')\n",
    "  \n",
    "\n",
    "# plot the accuracy Curves\n",
    "\n",
    "plt.figure(figsize=[8,6])\n",
    "\n",
    "plt.plot(r.history['accuracy'],'r',linewidth=3.0)\n",
    "\n",
    "plt.plot(r.history['val_accuracy'],'b',linewidth=3.0)\n",
    "\n",
    "plt.legend(['Training Accuracy', 'Validation Accuracy'],fontsize=18)\n",
    "\n",
    "plt.xlabel('Epochs ',fontsize=16)\n",
    "\n",
    "plt.ylabel('Accuracy',fontsize=16)\n",
    "\n",
    "plt.title('Accuracy Curves',fontsize=16)\n",
    "plt.savefig('Accuracy.png') \n",
    "\n",
    "def plot_confusion_matrix(cm, classes, normalize=False, title='Confusion matrix', cmap=plt.cm.Blues):\n",
    "\n",
    "    plt.figure(figsize=(10,10))\n",
    "\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "\n",
    "    plt.title(title)\n",
    "\n",
    "    plt.colorbar()\n",
    "\n",
    "\n",
    "    tick_marks = np.arange(len(classes))\n",
    "\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "\n",
    "    if normalize:\n",
    "\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "        print(\"Normalized confusion matrix\")\n",
    "\n",
    "    else:\n",
    "\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(7,7))\n",
    "    im = ax.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    ax.figure.colorbar(im, ax=ax)\n",
    "    ax.set(xticks=np.arange(cm.shape[1]),\n",
    "           yticks=np.arange(cm.shape[0]),\n",
    "           xticklabels=classes, yticklabels=classes,\n",
    "           title=title,\n",
    "           ylabel='True label',\n",
    "           xlabel='Predicted label')\n",
    "    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",\n",
    "             rotation_mode=\"anchor\")\n",
    "    \n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i in range(cm.shape[0]):\n",
    "        for j in range(cm.shape[1]):\n",
    "            ax.text(j, i, format(cm[i, j], fmt),\n",
    "                    ha=\"center\", va=\"center\",\n",
    "                    color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "    fig.tight_layout()\n",
    "    plt.savefig('Confusion Matrix.png')\n",
    "    return ax\n",
    "    \n",
    "np.set_printoptions(precision=2)\n",
    "\n",
    "#Print the Target names\n",
    "target_names = []\n",
    "\n",
    "for key in training_set.class_indices:\n",
    "\n",
    "    target_names.append(key)\n",
    "\n",
    "pred = model.predict(test_set,batch_size = 1)\n",
    "y_pred = np.argmax(pred, axis=1)\n",
    "\n",
    "print('Confusion Matrix')\n",
    "\n",
    "cm = confusion_matrix(test_set.classes, y_pred)\n",
    "print(cm)\n",
    "plot_confusion_matrix(cm, target_names, title='Confusion Matrix')\n",
    "\n",
    "print('Classification Report')\n",
    "\n",
    "print(classification_report(test_set.classes, y_pred, target_names=target_names))\n",
    "\n",
    "from itertools import cycle\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from scipy import interp\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# Compute ROC curve and ROC area for each class\n",
    "# roc curve for classes\n",
    "fpr = {}\n",
    "tpr = {}\n",
    "thresh ={}\n",
    "\n",
    "n_classes = 5\n",
    "\n",
    "for i in range(n_classes):    \n",
    "    fpr[i], tpr[i], thresh[i] = roc_curve(test_set.classes, pred[:,i], pos_label=i)\n",
    "    \n",
    "    \n",
    "# plotting    \n",
    "plt.plot(fpr[0], tpr[0], linestyle='--',color='orange', label='Class 0 vs Rest')\n",
    "plt.plot(fpr[1], tpr[1], linestyle='--',color='green', label='Class 1 vs Rest')\n",
    "plt.plot(fpr[2], tpr[2], linestyle='--',color='blue', label='Class 2 vs Rest')\n",
    "plt.plot(fpr[0], tpr[0], linestyle='--',color='black', label='Class 3 vs Rest')\n",
    "plt.plot(fpr[1], tpr[1], linestyle='--',color='pink', label='Class 4 vs Rest')\n",
    "plt.title('Multiclass ROC curve')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive rate')\n",
    "plt.ylim([0.96, 1.001])\n",
    "plt.legend(loc='best')\n",
    "plt.savefig('Multiclass_ROC_128',dpi=300) \n",
    "\n",
    "\n",
    "roc_auc = dict()\n",
    "for i in range(n_classes):\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "\n",
    "# First aggregate all false positive rates\n",
    "all_fpr = np.unique(np.concatenate([fpr[i] for i in range(n_classes)]))\n",
    "lw=2\n",
    "# Then interpolate all ROC curves at this points\n",
    "mean_tpr = np.zeros_like(all_fpr)\n",
    "for i in range(n_classes):\n",
    "    mean_tpr += np.interp(all_fpr, fpr[i], tpr[i])\n",
    "\n",
    "# Finally average it and compute AUC\n",
    "mean_tpr /= n_classes\n",
    "\n",
    "fpr[\"macro\"] = all_fpr\n",
    "tpr[\"macro\"] = mean_tpr\n",
    "roc_auc[\"macro\"] = auc(fpr[\"macro\"], tpr[\"macro\"])\n",
    "\n",
    "# Plot all ROC curves\n",
    "plt.figure()\n",
    "\n",
    "plt.plot(fpr[\"macro\"], tpr[\"macro\"],\n",
    "         label='macro-average ROC curve (area = {0:0.2f})'\n",
    "               ''.format(roc_auc[\"macro\"]),\n",
    "         color='navy', linestyle=':', linewidth=4)\n",
    "\n",
    "colors = cycle(['aqua', 'darkorange', 'cornflowerblue', 'green', 'blue', 'olive', 'brown', 'black', 'gray', 'purple'])\n",
    "for i, color in zip(range(n_classes), colors):\n",
    "    plt.plot(fpr[i], tpr[i], color=color, lw=lw,\n",
    "             label='ROC curve of class {0} (area = {1:0.2f})'\n",
    "             ''.format(i, roc_auc[i]))\n",
    "\n",
    "plt.plot([0, 1], [0, 1], 'k--', lw=lw)\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.0])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title(' Receiver operating characteristic')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.savefig('All_ROC_128',dpi=300); \n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
